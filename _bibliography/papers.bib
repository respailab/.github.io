---
---

@string{aps = {American Physical Society,}}

@article{tarun2023fast,
  abbr={IEEE},
  title={Fast yet effective machine unlearning},
  author={Tarun, Ayush K and Chundawat, Vikram S and Mandal, Murari and Kankanhalli, Mohan},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE},
  pdf={https://arxiv.org/pdf/2111.08947.pdf},
  selected={true}
}

@article{10097553,
  abbr={IEEE},
  author={Chundawat, Vikram S. and Tarun, Ayush K. and Mandal, Murari and Kankanhalli, Mohan},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Zero-Shot Machine Unlearning}, 
  year={2023},
  volume={18},
  number={},
  pages={2345-2354},
  keywords={Data models;Training;Data privacy;Training data;Computational modeling;Regulation;Machine learning;Machine unlearning;machine learning security and privacy;data privacy},
  doi={10.1109/TIFS.2023.3265506},
  pdf={https://arxiv.org/pdf/2201.05629.pdf},
  selected={true}
}

@InProceedings{pmlr-v202-tarun23a,
  title = 	 {Deep Regression Unlearning},
  author =       {Tarun, Ayush Kumar and Chundawat, Vikram Singh and Mandal, Murari and Kankanhalli, Mohan},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {33921--33939},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/tarun23a/tarun23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/tarun23a.html},
  abstract = 	 {With the introduction of data protection and privacy regulations, it has become crucial to remove the lineage of data on demand from a machine learning (ML) model. In the last few years, there have been notable developments in machine unlearning to remove the information of certain training data efficiently and effectively from ML models. In this work, we explore unlearning for the regression problem, particularly in deep learning models. Unlearning in classification and simple linear regression has been considerably investigated. However, unlearning in deep regression models largely remains an untouched problem till now. In this work, we introduce deep regression unlearning methods that generalize well and are robust to privacy attacks. We propose the Blindspot unlearning method which uses a novel weight optimization process. A randomly initialized model, partially exposed to the retain samples and a copy of the original model are used together to selectively imprint knowledge about the data that we wish to keep and scrub off the information of the data we wish to forget. We also propose a Gaussian fine tuning method for regression unlearning. The existing unlearning metrics for classification are not directly applicable to regression unlearning. Therefore, we adapt these metrics for the regression setting. We conduct regression unlearning experiments for computer vision, natural language processing and forecasting applications. Our methods show excellent performance for all these datasets across all the metrics. Source code: https://github.com/ayu987/deep-regression-unlearning}
}
